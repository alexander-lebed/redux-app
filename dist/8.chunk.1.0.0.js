(window["webpackJsonp"] = window["webpackJsonp"] || []).push([[8],{

/***/ "./node_modules/react-speech-recognition/lib/SpeechRecognition.js":
/*!************************************************************************!*\
  !*** ./node_modules/react-speech-recognition/lib/SpeechRecognition.js ***!
  \************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; };\n\nvar _createClass = (function () { function defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } } return function (Constructor, protoProps, staticProps) { if (protoProps) defineProperties(Constructor.prototype, protoProps); if (staticProps) defineProperties(Constructor, staticProps); return Constructor; }; })();\n\nexports.default = SpeechRecognition;\n\nvar _react = __webpack_require__(/*! react */ \"./node_modules/react/index.js\");\n\nvar _react2 = _interopRequireDefault(_react);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _possibleConstructorReturn(self, call) { if (!self) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return call && (typeof call === \"object\" || typeof call === \"function\") ? call : self; }\n\nfunction _inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function, not \" + typeof superClass); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, enumerable: false, writable: true, configurable: true } }); if (superClass) Object.setPrototypeOf ? Object.setPrototypeOf(subClass, superClass) : subClass.__proto__ = superClass; }\n\nfunction SpeechRecognition(options) {\n  var SpeechRecognitionInner = function SpeechRecognitionInner(WrappedComponent) {\n    var BrowserSpeechRecognition = typeof window !== 'undefined' && (window.SpeechRecognition || window.webkitSpeechRecognition || window.mozSpeechRecognition || window.msSpeechRecognition || window.oSpeechRecognition);\n    var recognition = BrowserSpeechRecognition ? new BrowserSpeechRecognition() : null;\n    var browserSupportsSpeechRecognition = recognition !== null;\n    var listening = undefined;\n    if (!browserSupportsSpeechRecognition || options && options.autoStart === false) {\n      listening = false;\n    } else {\n      recognition.start();\n      listening = true;\n    }\n    var pauseAfterDisconnect = false;\n    var interimTranscript = '';\n    var finalTranscript = '';\n\n    return (function (_Component) {\n      _inherits(SpeechRecognitionContainer, _Component);\n\n      function SpeechRecognitionContainer(props) {\n        _classCallCheck(this, SpeechRecognitionContainer);\n\n        var _this = _possibleConstructorReturn(this, (SpeechRecognitionContainer.__proto__ || Object.getPrototypeOf(SpeechRecognitionContainer)).call(this, props));\n\n        _this.disconnect = function (disconnectType) {\n          if (recognition) {\n            switch (disconnectType) {\n              case 'ABORT':\n                pauseAfterDisconnect = true;\n                recognition.abort();\n                break;\n              case 'RESET':\n                pauseAfterDisconnect = false;\n                recognition.abort();\n                break;\n              case 'STOP':\n              default:\n                pauseAfterDisconnect = true;\n                recognition.stop();\n            }\n          }\n        };\n\n        _this.resetTranscript = function () {\n          interimTranscript = '';\n          finalTranscript = '';\n          _this.disconnect('RESET');\n          _this.setState({ interimTranscript: interimTranscript, finalTranscript: finalTranscript });\n        };\n\n        _this.startListening = function () {\n          if (recognition && !listening) {\n            if (!recognition.continuous) {\n              _this.resetTranscript();\n            }\n            try {\n              recognition.start();\n            } catch (DOMException) {\n              // Tried to start recognition after it has already started - safe to swallow this error\n            }\n            listening = true;\n            _this.setState({ listening: listening });\n          }\n        };\n\n        _this.abortListening = function () {\n          listening = false;\n          _this.setState({ listening: listening });\n          _this.disconnect('ABORT');\n        };\n\n        _this.stopListening = function () {\n          listening = false;\n          _this.setState({ listening: listening });\n          _this.disconnect('STOP');\n        };\n\n        if (browserSupportsSpeechRecognition) {\n          recognition.continuous = options.continuous !== false;\n          recognition.interimResults = true;\n          recognition.onresult = _this.updateTranscript.bind(_this);\n          recognition.onend = _this.onRecognitionDisconnect.bind(_this);\n        }\n\n        _this.state = {\n          interimTranscript: interimTranscript,\n          finalTranscript: finalTranscript,\n          listening: listening\n        };\n        return _this;\n      }\n\n      _createClass(SpeechRecognitionContainer, [{\n        key: 'onRecognitionDisconnect',\n        value: function onRecognitionDisconnect() {\n          listening = false;\n          if (pauseAfterDisconnect) {\n            this.setState({ listening: listening });\n          } else if (recognition) {\n            if (recognition.continuous) {\n              this.startListening();\n            } else {\n              this.setState({ listening: listening });\n            }\n          }\n          pauseAfterDisconnect = false;\n        }\n      }, {\n        key: 'updateTranscript',\n        value: function updateTranscript(event) {\n          interimTranscript = '';\n          for (var i = event.resultIndex; i < event.results.length; ++i) {\n            if (event.results[i].isFinal) {\n              finalTranscript = this.concatTranscripts(finalTranscript, event.results[i][0].transcript);\n            } else {\n              interimTranscript = this.concatTranscripts(interimTranscript, event.results[i][0].transcript);\n            }\n          }\n          this.setState({ finalTranscript: finalTranscript, interimTranscript: interimTranscript });\n        }\n      }, {\n        key: 'concatTranscripts',\n        value: function concatTranscripts() {\n          for (var _len = arguments.length, transcriptParts = Array(_len), _key = 0; _key < _len; _key++) {\n            transcriptParts[_key] = arguments[_key];\n          }\n\n          return transcriptParts.map(function (t) {\n            return t.trim();\n          }).join(' ').trim();\n        }\n      }, {\n        key: 'render',\n        value: function render() {\n          var transcript = this.concatTranscripts(finalTranscript, interimTranscript);\n\n          return _react2.default.createElement(WrappedComponent, _extends({\n            resetTranscript: this.resetTranscript,\n            startListening: this.startListening,\n            abortListening: this.abortListening,\n            stopListening: this.stopListening,\n            transcript: transcript,\n            recognition: recognition,\n            browserSupportsSpeechRecognition: browserSupportsSpeechRecognition\n          }, this.state, this.props));\n        }\n      }]);\n\n      return SpeechRecognitionContainer;\n    })(_react.Component);\n  };\n\n  if (typeof options === 'function') {\n    return SpeechRecognitionInner(options);\n  } else {\n    return SpeechRecognitionInner;\n  }\n}\n\n//# sourceURL=webpack:///./node_modules/react-speech-recognition/lib/SpeechRecognition.js?");

/***/ }),

/***/ "./node_modules/react-speech-recognition/lib/index.js":
/*!************************************************************!*\
  !*** ./node_modules/react-speech-recognition/lib/index.js ***!
  \************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar _SpeechRecognition = __webpack_require__(/*! ./SpeechRecognition */ \"./node_modules/react-speech-recognition/lib/SpeechRecognition.js\");\n\nvar _SpeechRecognition2 = _interopRequireDefault(_SpeechRecognition);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nexports.default = _SpeechRecognition2.default;\n\n//# sourceURL=webpack:///./node_modules/react-speech-recognition/lib/index.js?");

/***/ }),

/***/ "./src/components/Dictaphone/index.js":
/*!********************************************!*\
  !*** ./src/components/Dictaphone/index.js ***!
  \********************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var react__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! react */ \"./node_modules/react/index.js\");\n/* harmony import */ var react__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(react__WEBPACK_IMPORTED_MODULE_0__);\n/* harmony import */ var react_speech_recognition__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! react-speech-recognition */ \"./node_modules/react-speech-recognition/lib/index.js\");\n/* harmony import */ var react_speech_recognition__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(react_speech_recognition__WEBPACK_IMPORTED_MODULE_1__);\n\n\n\nvar Dictaphone = function Dictaphone(_ref) {\n  var listening = _ref.listening,\n      transcript = _ref.transcript,\n      startListening = _ref.startListening,\n      stopListening = _ref.stopListening,\n      resetTranscript = _ref.resetTranscript,\n      browserSupportsSpeechRecognition = _ref.browserSupportsSpeechRecognition,\n      onSpeach = _ref.onSpeach;\n\n  if (!browserSupportsSpeechRecognition) {\n    return null;\n  }\n\n  Object(react__WEBPACK_IMPORTED_MODULE_0__[\"useEffect\"])(function () {\n    if (listening) {\n      onSpeach(transcript);\n    }\n  }, [listening, transcript]);\n  return react__WEBPACK_IMPORTED_MODULE_0___default.a.createElement(\"div\", null, listening ? null : react__WEBPACK_IMPORTED_MODULE_0___default.a.createElement(\"i\", {\n    className: \"fas fa-microphone\",\n    onClick: startListening\n  }), react__WEBPACK_IMPORTED_MODULE_0___default.a.createElement(\"button\", {\n    onClick: stopListening\n  }, \"Stop\"));\n};\n\n/* harmony default export */ __webpack_exports__[\"default\"] = (react_speech_recognition__WEBPACK_IMPORTED_MODULE_1___default()({\n  autoStart: false,\n  continuous: false\n})(Dictaphone));\n\n//# sourceURL=webpack:///./src/components/Dictaphone/index.js?");

/***/ })

}]);